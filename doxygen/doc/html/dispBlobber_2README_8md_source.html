<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>segmentation: /home/runner/work/segmentation/segmentation/gh-pages/dispBlobber/README.md Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">segmentation
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
</div><!-- top -->
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">/home/runner/work/segmentation/segmentation/gh-pages/dispBlobber/README.md</div>  </div>
</div><!--header-->
<div class="contents">
<div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;dispBlobber</div><div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;====================</div><div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;</div><div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;Module to detect the closest proto-object in the robot&#39;s visual field using stereo-vision.</div><div class="line"><a name="l00005"></a><span class="lineno">    5</span>&#160;</div><div class="line"><a name="l00006"></a><span class="lineno">    6</span>&#160;## Description</div><div class="line"><a name="l00007"></a><span class="lineno">    7</span>&#160;</div><div class="line"><a name="l00008"></a><span class="lineno">    8</span>&#160;This module takes as input a disparity map (grayscale image) and provides as output the closest (brightest) blob, which is generally an object or proto-object in the scene. The output is provided in the following forms:</div><div class="line"><a name="l00009"></a><span class="lineno">    9</span>&#160;</div><div class="line"><a name="l00010"></a><span class="lineno">   10</span>&#160;- binary image with the segmented blob</div><div class="line"><a name="l00011"></a><span class="lineno">   11</span>&#160;- cropped rectangular region enclosing the segmented blob on the input disparity map</div><div class="line"><a name="l00012"></a><span class="lineno">   12</span>&#160;- 2D top-left (TL) and bottom-right (BR) pixel coordinates of the cropped rectangular region on the input disparity map -eventually averaged over a frame buffer of arbitrary size-</div><div class="line"><a name="l00013"></a><span class="lineno">   13</span>&#160;- 2D pixel coordinates of the centroid of the segmented blob -eventually averaged over the same frame buffer- on the input disparity map</div><div class="line"><a name="l00014"></a><span class="lineno">   14</span>&#160;</div><div class="line"><a name="l00015"></a><span class="lineno">   15</span>&#160;If the input disparity map comes from the [SFM](https://github.com/robotology/stereo-vision) module and this module is connected to the RPC port of the [SFM](https://github.com/robotology/stereo-vision), then  the stereo pairs (correspondent 2D points on the other camera) and the 3D re-projections in the world reference frame of the above points (blob&#39;s TL and BR ROI vertices and centroid) are also provided as output.</div><div class="line"><a name="l00016"></a><span class="lineno">   16</span>&#160;</div><div class="line"><a name="l00017"></a><span class="lineno">   17</span>&#160;The centroid&#39;s coordinates of the closest blob in the scene provided by this module can be fed to the [ARE](http://wiki.icub.org/iCub_documentation/group__actionsRenderingEngine.html) or directly to the [iKinGazeCtrl](http://wiki.icub.org/iCub_documentation/group__iKinGazeCtrl.html) module in order to focus the robot&#39;s gaze on the object of interest. If the data connection is streamlined then the robot keeps on focusing on the closest proto-object in its visual field.</div><div class="line"><a name="l00018"></a><span class="lineno">   18</span>&#160;</div><div class="line"><a name="l00019"></a><span class="lineno">   19</span>&#160;Example applications of the usage of this module can be found here:</div><div class="line"><a name="l00020"></a><span class="lineno">   20</span>&#160;- [onthefly-recognition](https://github.com/robotology/onthefly-recognition): demo to teach the iCub to recognize new objects on-the-fly.</div><div class="line"><a name="l00021"></a><span class="lineno">   21</span>&#160;- [icubworld](https://github.com/GiuliaP/icubworld): application to acquire a dataset of images from the iCub&#39;s cameras while the robot is observing a set of objects shown by a human operator. The dataset can be used, e.g., to train/benchmark offline a visual recognition system.</div><div class="line"><a name="l00022"></a><span class="lineno">   22</span>&#160;</div></div><!-- fragment --></div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.13
</small></address>
</body>
</html>
